// @ts-nocheck
import { Plugin } from 'vite'

// ç”Ÿæˆæ ‡å‡† WAV é™éŸ³ï¼ˆæ— éœ€ç¬¬ä¸‰æ–¹ä¾èµ–ï¼Œä¿è¯å¯æ’­æ”¾ï¼‰
function createSilentWav(durationSeconds: number): Buffer {
  const sampleRate = 44100
  const numChannels = 1
  const bytesPerSample = 2 // 16-bit PCM
  const numSamples = Math.max(1, Math.floor(sampleRate * durationSeconds))

  const dataSize = numSamples * numChannels * bytesPerSample
  const buffer = Buffer.alloc(44 + dataSize)
  let offset = 0

  function writeString(str: string) {
    buffer.write(str, offset); offset += str.length
  }
  function writeUint32(v: number) {
    buffer.writeUInt32LE(v, offset); offset += 4
  }
  function writeUint16(v: number) {
    buffer.writeUInt16LE(v, offset); offset += 2
  }

  // RIFF header
  writeString('RIFF')
  writeUint32(36 + dataSize)
  writeString('WAVE')

  // fmt chunk
  writeString('fmt ')
  writeUint32(16) // PCM
  writeUint16(1)  // audio format = PCM
  writeUint16(numChannels)
  writeUint32(sampleRate)
  writeUint32(sampleRate * numChannels * bytesPerSample) // byte rate
  writeUint16(numChannels * bytesPerSample) // block align
  writeUint16(8 * bytesPerSample) // bits per sample

  // data chunk
  writeString('data')
  writeUint32(dataSize)

  // å†™å…¥é™éŸ³ï¼ˆå…¨0ï¼‰
  // Buffer å·²ç»æ˜¯ 0 å¡«å……ï¼Œæ— éœ€å†å†™

  return buffer
}

// è§£æ16-bit PCM WAVï¼Œè¿”å›åŸºç¡€ä¿¡æ¯ä¸PCMæ•°æ®
function parsePcmWav(wavBuffer: Buffer): {
  sampleRate: number
  numChannels: number
  bitsPerSample: number
  pcm: Int16Array
} {
  // RIFF/WAVE æ ¡éªŒ
  if (wavBuffer.toString('ascii', 0, 4) !== 'RIFF' || wavBuffer.toString('ascii', 8, 12) !== 'WAVE') {
    throw new Error('Invalid WAV: Missing RIFF/WAVE header')
  }

  // è§£æ chunks
  let offset = 12 // è·³è¿‡ RIFF header
  let fmtChunkFound = false
  let dataChunkOffset = -1
  let dataChunkSize = 0
  let audioFormat = 0
  let numChannels = 0
  let sampleRate = 0
  let bitsPerSample = 0

  while (offset + 8 <= wavBuffer.length) {
    const chunkId = wavBuffer.toString('ascii', offset, offset + 4)
    const chunkSize = wavBuffer.readUInt32LE(offset + 4)
    const chunkDataStart = offset + 8
    const chunkDataEnd = chunkDataStart + chunkSize

    if (chunkId === 'fmt ') {
      fmtChunkFound = true
      audioFormat = wavBuffer.readUInt16LE(chunkDataStart)
      numChannels = wavBuffer.readUInt16LE(chunkDataStart + 2)
      sampleRate = wavBuffer.readUInt32LE(chunkDataStart + 4)
      bitsPerSample = wavBuffer.readUInt16LE(chunkDataStart + 14)
    } else if (chunkId === 'data') {
      dataChunkOffset = chunkDataStart
      dataChunkSize = chunkSize
      // ä¸ breakï¼Œç»§ç»­å¤„ç†åç»­ chunkï¼ˆé€šå¸¸å·²è¶³å¤Ÿï¼‰
    }

    offset = chunkDataEnd
  }

  if (!fmtChunkFound || dataChunkOffset < 0) {
    throw new Error('Invalid WAV: Missing fmt or data chunk')
  }
  if (audioFormat !== 1) {
    throw new Error(`Unsupported WAV format: ${audioFormat} (expect PCM=1)`) 
  }
  if (bitsPerSample !== 16) {
    throw new Error(`Unsupported bits per sample: ${bitsPerSample} (expect 16)`) 
  }

  const dataBuf = wavBuffer.subarray(dataChunkOffset, dataChunkOffset + dataChunkSize)
  // 16-bit little-endian PCM
  const pcm = new Int16Array(dataBuf.buffer, dataBuf.byteOffset, Math.floor(dataBuf.byteLength / 2))

  return { sampleRate, numChannels, bitsPerSample, pcm }
}

// å°† Int16 PCM å†™ä¸ºæ ‡å‡† WAV Buffer
function createWavFromPcm(pcm: Int16Array, sampleRate: number, numChannels: number): Buffer {
  const bytesPerSample = 2
  const dataSize = pcm.length * bytesPerSample
  const buffer = Buffer.alloc(44 + dataSize)
  let offset = 0

  function writeString(str: string) {
    buffer.write(str, offset); offset += str.length
  }
  function writeUint32(v: number) {
    buffer.writeUInt32LE(v, offset); offset += 4
  }
  function writeUint16(v: number) {
    buffer.writeUInt16LE(v, offset); offset += 2
  }

  writeString('RIFF')
  writeUint32(36 + dataSize)
  writeString('WAVE')

  writeString('fmt ')
  writeUint32(16)
  writeUint16(1) // PCM
  writeUint16(numChannels)
  writeUint32(sampleRate)
  writeUint32(sampleRate * numChannels * bytesPerSample)
  writeUint16(numChannels * bytesPerSample)
  writeUint16(8 * bytesPerSample)

  writeString('data')
  writeUint32(dataSize)

  // å†™å…¥PCMæ•°æ®ï¼ˆInt16 -> little-endianï¼‰
  for (let i = 0; i < pcm.length; i++) {
    buffer.writeInt16LE(pcm[i], offset)
    offset += 2
  }

  return buffer
}

// ç”ŸæˆæŒ‡å®šæ—¶é•¿çš„é™éŸ³PCMï¼ˆInt16ï¼‰
function createSilentPcm(durationSeconds: number, sampleRate: number, numChannels: number): Int16Array {
  const totalSamples = Math.max(0, Math.floor(durationSeconds * sampleRate * numChannels))
  return new Int16Array(totalSamples) // å…¨0 å³é™éŸ³
}

// Viteæ’ä»¶ï¼šæä¾›æœ¬åœ°TTSä»£ç†æœåŠ¡
function registerTtsRoutes(server: { middlewares: any }) {
  server.middlewares.use('/api/tts', async (req: any, res: any) => {
        // å¤„ç†é¢„æ£€è¯·æ±‚
        if (req.method === 'OPTIONS') {
          res.statusCode = 204
          res.setHeader('Access-Control-Allow-Origin', '*')
          res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
          res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
          res.end()
          return
        }
        // åªæ¥å—POSTè¯·æ±‚
        if (req.method !== 'POST') {
          // å…¼å®¹ GET ç®€å•è°ƒè¯•
          if (req.method === 'GET') {
            // å…è®¸GETä½œä¸ºå¥åº·æ£€æŸ¥æˆ–ç®€å•è°ƒç”¨
          } else {
            res.statusCode = 405
            res.end(JSON.stringify({ error: 'Method Not Allowed' }))
            return
          }
        }

        try {
          // è¯»å–POST body
          let body = ''
          req.on('data', chunk => { body += chunk.toString() })
          
          await new Promise<void>((resolve) => {
            req.on('end', () => resolve())
          })

          const data = JSON.parse(body || '{}')
          let { text, lang = 'en-US', voice = 'Cherry' } = data

          if (!text || typeof text !== 'string') {
            res.statusCode = 400
            res.end(JSON.stringify({ error: 'text is required' }))
            return
          }

          // CORS headersï¼ˆå¼€å‘ç¯å¢ƒä¸‹ä¾¿äºæœ¬åœ°è°ƒç”¨ï¼‰
          res.setHeader('Access-Control-Allow-Origin', '*')
          res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
          res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')

          console.log(`ğŸ™ï¸ TTSè¯·æ±‚: text="${text.substring(0, 50)}...", lang=${lang}, voice=${voice}`)
          
          // è°ƒç”¨é€šä¹‰åƒé—®TTS API
          const qwenApiKey = process.env.DASHSCOPE_API_KEY || ''
          if (!qwenApiKey) {
            res.statusCode = 500
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({ error: 'Missing DASHSCOPE_API_KEY (dev)', hint: 'åœ¨æœ¬åœ°ç»ˆç«¯è®¾ç½®ç¯å¢ƒå˜é‡åé‡å¯ï¼šset DASHSCOPE_API_KEY=ä½ çš„Key' }))
            return
          }
          const qwenModel = 'qwen3-tts-flash'
          
          // æ£€æµ‹æ˜¯å¦ä¸ºä¸­è‹±æ··åˆæ–‡æœ¬ï¼ˆåŒ…å«æ±‰å­—å’Œè‹±æ–‡å­—æ¯ï¼‰
          const hasChinese = /[\u4e00-\u9fa5]/.test(text)
          const hasEnglish = /[a-zA-Z]/.test(text)
          const isMixed = hasChinese && hasEnglish
          
          // ç¡®å®šè¯­è¨€ç±»å‹ï¼šæ··åˆæ–‡æœ¬ç”¨Autoï¼Œå•ä¸€è¯­è¨€ç”¨æŒ‡å®šç±»å‹
          let languageType = 'Auto'
          if (!isMixed) {
            languageType = lang.includes('zh') ? 'Chinese' : 'English'
          }
          
          console.log(`ğŸŒ è¯­è¨€æ£€æµ‹: ä¸­æ–‡=${hasChinese}, è‹±æ–‡=${hasEnglish}, æ··åˆ=${isMixed}, ä½¿ç”¨=${languageType}`)
          
          async function callUpstream(currVoice: string) {
            return await fetch(
            'https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation',
            {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${qwenApiKey}`,
              },
              body: JSON.stringify({
                model: qwenModel,
                input: { 
                  text: text,
                  language_type: languageType,
                  voice: currVoice
                },
                audio: {
                  format: 'mp3',
                  sample_rate: 24000
                }
              })
            }
          )
          }

          // ç¬¬ä¸€æ¬¡è°ƒç”¨
          let upstream = await callUpstream(voice)

          const upstreamData = await upstream.json().catch(async () => ({ raw: await upstream.text().catch(() => '') })) as any

          // é€ä¼ ä¸Šæ¸¸é”™è¯¯
          if (!upstream.ok) {
            const msg: string = upstreamData?.message || ''
            // å¦‚æœå‘éŸ³äººä¸æ”¯æŒï¼Œåˆ™è‡ªåŠ¨å›é€€åˆ° Cherry é‡è¯•ä¸€æ¬¡
            if (/Voice .* is not supported/i.test(msg) && voice !== 'Cherry') {
              console.warn('âš ï¸ å‘éŸ³äººä¸æ”¯æŒï¼Œè‡ªåŠ¨å›é€€åˆ° Cherry å¹¶é‡è¯•ä¸€æ¬¡')
              voice = 'Cherry'
              upstream = await callUpstream(voice)
              const retried = await upstream.json().catch(() => ({})) as any
              if (!upstream.ok) {
                console.error(`âŒ ä¸Šæ¸¸TTSé”™è¯¯(é‡è¯•å) ${upstream.status}:`, retried)
                res.statusCode = upstream.status
                res.setHeader('Content-Type', 'application/json')
                res.end(JSON.stringify({
                  error: retried?.message || retried?.code || 'Upstream error',
                  upstream: retried
                }))
                return
              } else {
                // æˆåŠŸèµ°åç»­é€šè·¯
                upstreamData.output = retried?.output
              }
            } else {
            console.error(`âŒ ä¸Šæ¸¸TTSé”™è¯¯ ${upstream.status}:`, upstreamData)
            res.statusCode = upstream.status
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({
              error: upstreamData?.message || upstreamData?.code || upstreamData?.raw || 'Upstream error',
              upstream: upstreamData
            }))
            return
            }
          }

          // æˆåŠŸï¼šè¿”å›éŸ³é¢‘URLæˆ–Base64ï¼ˆå…¼å®¹ä¸åŒè¿”å›ç»“æ„ï¼‰
          const audioUrl = upstreamData?.output?.audio?.url ?? upstreamData?.output?.audio_url
          const audioBase64 = upstreamData?.output?.audio?.data

          if (audioUrl) {
            console.log(`âœ… TTSæˆåŠŸï¼Œè¿”å›URL: ${audioUrl.substring(0, 50)}...`)
            res.statusCode = 200
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({ audioUrl }))
          } else if (audioBase64) {
            console.log(`âœ… TTSæˆåŠŸï¼Œè¿”å›Base64 (${audioBase64.length} chars)`)
            res.statusCode = 200
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({ audioBase64 }))
          } else {
            // å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›å¯æ’­æ”¾çš„ WAV é™éŸ³å ä½ï¼Œå¹¶é™„å¸¦ä¸Šæ¸¸å›åŒ…æ–¹ä¾¿æ’æŸ¥
            console.warn('âš ï¸ ä¸Šæ¸¸æœªè¿”å›éŸ³é¢‘å­—æ®µï¼Œè¿”å›é™éŸ³WAVå ä½; upstreamData=', upstreamData)
            const duration = Math.max(1, text.length * 0.1)
            const wavBuffer = createSilentWav(duration)
            res.statusCode = 200
            res.setHeader('Content-Type', 'audio/wav')
            res.setHeader('X-Upstream-Info', encodeURIComponent(JSON.stringify(upstreamData).slice(0,512)))
            res.setHeader('Cache-Control', 'no-store')
            res.end(wavBuffer)
          }
          
        } catch (error: any) {
          console.error('TTSå¤„ç†é”™è¯¯:', error)
          res.statusCode = 502
          res.setHeader('Content-Type', 'application/json')
          res.end(JSON.stringify({ 
            error: 'Upstream TTS call failed', 
            detail: String(error) 
          }))
        }
  })

  // æ‰¹é‡TTSï¼šé€è¯åˆæˆï¼ŒæŒ‰é—´éš”æ‹¼æ¥åä¸€æ¬¡æ€§è¿”å›å•ä¸ªWAV
  server.middlewares.use('/api/tts-batch', async (req: any, res: any) => {
        // å¤„ç†é¢„æ£€è¯·æ±‚
        if (req.method === 'OPTIONS') {
          res.statusCode = 204
          res.setHeader('Access-Control-Allow-Origin', '*')
          res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
          res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
          res.end()
          return
        }
        if (req.method !== 'POST') {
          // å…¼å®¹ GET è°ƒç”¨ï¼Œå…è®¸é€šè¿‡æŸ¥è¯¢ä¸²ä¼ å‚
          if (req.method === 'GET') {
            // pass
          } else {
            res.statusCode = 405
            res.end(JSON.stringify({ error: 'Method Not Allowed' }))
            return
          }
        }

        try {
          // CORS headers
          res.setHeader('Access-Control-Allow-Origin', '*')
          res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
          res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')

          let data: any = {}
          if (req.method === 'POST') {
            let body = ''
            req.on('data', chunk => { body += chunk.toString() })
            await new Promise<void>((resolve) => { req.on('end', () => resolve()) })
            try { data = JSON.parse(body || '{}') } catch { data = {} }
          } else {
            // GET: ä»æŸ¥è¯¢ä¸²è¯»å–
            const u = new URL(req.url || '', 'http://localhost')
            const wordsParam = u.searchParams.getAll('w')
            const wordsJson = u.searchParams.get('words')
            const lang = u.searchParams.get('lang') || undefined
            const voice = u.searchParams.get('voice') || undefined
            const rate = u.searchParams.get('rate')
            const gapMs = u.searchParams.get('gapMs')
            let words: string[] = []
            if (wordsJson) {
              try { const parsed = JSON.parse(wordsJson); if (Array.isArray(parsed)) words = parsed.map(String) } catch {}
            }
            if (wordsParam.length) words = words.concat(wordsParam)
            data = {
              words,
              lang,
              voice,
              rate: rate ? Number(rate) : undefined,
              gapMs: gapMs ? Number(gapMs) : undefined
            }
          }
          // æ”¯æŒ words: string[] æˆ– items: { text: string }[]
          const words: string[] = Array.isArray(data?.words)
            ? (data.words as any[]).map(x => String(x)).filter(Boolean)
            : Array.isArray(data?.items)
              ? (data.items as any[]).map(x => String(x?.text || '')).filter(Boolean)
              : []

          if (!words.length) {
            res.statusCode = 400
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({ error: 'words or items is required' }))
            return
          }

          let { lang = 'en-US', voice = 'Cherry', rate = 1.0, gapMs = 600 } = data || {}

          // ç»Ÿä¸€å‚æ•°
          const desiredSampleRate = 24000
          const desiredChannels = 1
          const gapSeconds = Math.max(0, Number(gapMs) || 0) / 1000

          // è¯­è¨€æ£€æµ‹ï¼šè‹¥æ··åˆåˆ™Autoï¼Œå¦åˆ™æŒ‰langæ¨æ–­
          
          // è¯­è¨€æ£€æµ‹ï¼šè‹¥æ··åˆåˆ™Autoï¼Œå¦åˆ™æŒ‰langæ¨æ–­
          const hasChinese = words.some(w => /[\u4e00-\u9fa5]/.test(w))
          const hasEnglish = words.some(w => /[a-zA-Z]/.test(w))
          const isMixed = hasChinese && hasEnglish
          let languageType = 'Auto'
          if (!isMixed) {
            languageType = String(lang).includes('zh') ? 'Chinese' : 'English'
          }

          async function callUpstreamWord(text: string): Promise<Buffer> {
            // ä¼˜å…ˆè¯·æ±‚WAVï¼Œä¾¿äºæ‹¼æ¥ã€‚å°è¯•æºå¸¦é€Ÿåº¦å‚æ•°ï¼ˆè‹¥ä¸æ”¯æŒä¼šå›é€€ï¼‰ã€‚
            const requestBodyBase: any = {
              model: 'qwen3-tts-flash',
              input: {
                text,
                language_type: languageType,
                voice
              },
              audio: {
                format: 'wav',
                sample_rate: desiredSampleRate
              }
            }

            // æœ€ä½³åŠªåŠ›åœ°ä¼ å…¥é€Ÿåº¦å‚æ•°ï¼ˆè‹¥ä¸Šæ¸¸ä¸æ”¯æŒä¼šå›é€€ä¸å¸¦æ­¤å‚æ•°ï¼‰
            if (typeof rate === 'number' && rate > 0 && rate !== 1) {
              try {
                requestBodyBase.audio.speed_ratio = rate
              } catch { /* no-op */ }
            }

            const upstream = await fetch(
              'https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation',
              {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  'Authorization': `Bearer ${'sk-9420fd983635418082464a07c80b0a15'}`,
                },
                body: JSON.stringify(requestBodyBase)
              }
            )

            const resp = await upstream.json().catch(() => ({})) as any

            if (!upstream.ok) {
              // è‹¥å› æœªçŸ¥å­—æ®µæŠ¥é”™ï¼Œå›é€€å»æ‰speed_ratioå†è¯•ä¸€æ¬¡
              const msg: string = resp?.message || ''
              if (msg && /speed|ratio|unknown|invalid/i.test(msg) && requestBodyBase?.audio?.speed_ratio) {
                delete requestBodyBase.audio.speed_ratio
                const retry = await fetch(
                  'https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation',
                  {
                    method: 'POST',
                    headers: {
                      'Content-Type': 'application/json',
                      'Authorization': `Bearer ${'sk-9420fd983635418082464a07c80b0a15'}`,
                    },
                    body: JSON.stringify(requestBodyBase)
                  }
                )
                const retried = await retry.json().catch(() => ({})) as any
                if (!retry.ok) {
                  throw new Error(`Upstream error: ${retry.status} ${retried?.message || retried?.code || ''}`)
                }
                // success path continues with retried data
                return await resolveAudioBufferFromUpstream(retried)
              }
              throw new Error(`Upstream error: ${upstream.status} ${msg || resp?.code || ''}`)
            }

            return await resolveAudioBufferFromUpstream(resp)
          }

          async function resolveAudioBufferFromUpstream(upstreamData: any): Promise<Buffer> {
            const audioUrl = upstreamData?.output?.audio?.url ?? upstreamData?.output?.audio_url
            const audioBase64 = upstreamData?.output?.audio?.data
            if (audioUrl) {
              const r = await fetch(audioUrl)
              if (!r.ok) throw new Error(`Fetch audioUrl failed: ${r.status}`)
              const arrBuf = await r.arrayBuffer()
              return Buffer.from(arrBuf)
            } else if (audioBase64) {
              return Buffer.from(audioBase64, 'base64')
            }
            throw new Error('Upstream returned no audio')
          }

          const segments: Int16Array[] = []
          let mergedMs = 0

          for (let i = 0; i < words.length; i++) {
            const word = String(words[i] || '')
            if (!word) continue

            const wavBuf = await callUpstreamWord(word)
            const { sampleRate, numChannels, bitsPerSample, pcm } = parsePcmWav(wavBuf)
            if (bitsPerSample !== 16) {
              throw new Error(`Unsupported bits: ${bitsPerSample}`)
            }
            if (sampleRate !== desiredSampleRate) {
              throw new Error(`Sample rate mismatch: got ${sampleRate}, expect ${desiredSampleRate}`)
            }
            if (numChannels !== desiredChannels) {
              throw new Error(`Channel mismatch: got ${numChannels}, expect ${desiredChannels}`)
            }

            segments.push(pcm)
            mergedMs += (pcm.length / (desiredSampleRate * desiredChannels)) * 1000

            // é—´éš”ï¼ˆæœ€åä¸€ä¸ªè¯åä¹Ÿå¯é€‰æ˜¯å¦åŠ å…¥ï¼Œè¿™é‡Œä¸åŠ å°¾éƒ¨é—´éš”ï¼‰
            if (gapSeconds > 0 && i < words.length - 1) {
              const gapPcm = createSilentPcm(gapSeconds, desiredSampleRate, desiredChannels)
              segments.push(gapPcm)
              mergedMs += gapSeconds * 1000
            }
          }

          if (segments.length === 0 || mergedMs < 1) {
            res.statusCode = 502
            res.setHeader('Content-Type', 'application/json')
            res.end(JSON.stringify({ error: 'No audio merged from upstream' }))
            return
          }

          // åˆå¹¶æ‰€æœ‰ PCM æ®µ
          const totalSamples = segments.reduce((sum, seg) => sum + seg.length, 0)
          const merged = new Int16Array(totalSamples)
          let writePos = 0
          for (const seg of segments) {
            merged.set(seg, writePos)
            writePos += seg.length
          }

          const wav = createWavFromPcm(merged, desiredSampleRate, desiredChannels)
          res.statusCode = 200
          res.setHeader('Content-Type', 'audio/wav')
          res.setHeader('Cache-Control', 'no-store')
          res.setHeader('X-Route', 'tts-batch')
          res.setHeader('X-Words-Count', String(words.length))
          res.setHeader('X-Audio-Duration-MS', String(Math.round(mergedMs)))
          res.end(wav)
        } catch (error: any) {
          console.error('TTSæ‰¹é‡å¤„ç†é”™è¯¯:', error)
          res.statusCode = 502
          res.setHeader('Content-Type', 'application/json')
          res.end(JSON.stringify({ 
            error: 'Batch TTS failed',
            detail: String(error)
          }))
        }
  })
}

export function ttsProxyPlugin(): Plugin {
  return {
    name: 'tts-proxy',
    configureServer(server) {
      registerTtsRoutes(server)
    },
    configurePreviewServer(server) {
      registerTtsRoutes(server)
    }
  }
}

